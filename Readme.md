# 🧠 ML Algorithms From Scratch — My Learning Repository

Welcome to my small corner of machine learning — a simple, math-driven repository where I’m implementing **core ML algorithms from scratch**, step by step.

This project isn’t about building production-ready models or fancy deep-learning pipelines.
It’s about going **back to the roots** — understanding the math behind each algorithm,
and writing out the logic in **pure Python**, using only the most basic tools.

---

## 🎯 Purpose

This repository is my personal exploration of:

- Strengthening my **Python coding** skills
- Deepening my understanding of **mathematical foundations** in machine learning
- Building algorithms **from first principles** (without relying on frameworks)

These are **clean, minimal implementations** written out of curiosity and love for math.

---

## 🧮 What You’ll Find Here

- Classic algorithms like:
  - Linear Regression (Batch, Stochastic, and Mini-batch Gradient Descent)
  - Logistic Regression
  - K-Nearest Neighbors (KNN)
  - K-Means Clustering
  - Naive Bayes
  - Perceptron
  - And more as I learn them

Each implementation focuses on:

- **Mathematical clarity**
- **Step-by-step gradient derivations**
- **Readable, well-commented code**

---

## 🧰 Libraries Used

I’m keeping it simple — no TensorFlow, no PyTorch, no Scikit-learn (unless for comparison later).

Only essentials:

- `numpy` — for math and matrix operations
- `pandas` — for handling small datasets
- `matplotlib` & `seaborn` — for visualizations

If a concept needs a more advanced tool in the future, I’ll add it responsibly — but the main goal stays **mathematical purity** and **coding practice**.

---

## 🧠 Philosophy

> “If you can’t derive it, you don’t really understand it.”

This repository is my way of internalizing machine learning — not by memorizing APIs,
but by re-creating the logic that makes those APIs possible.

---
